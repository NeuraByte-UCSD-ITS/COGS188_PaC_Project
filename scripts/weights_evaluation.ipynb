import tensorflow as tf
import pandas as pd
import numpy as np
import h5py
import os

# Define the DQN model architecture used in dqn.py and dqn_agent.py
class DQN(tf.keras.Model):
    def __init__(self, action_space_size):
        super(DQN, self).__init__()
        self.dense1 = tf.keras.layers.Dense(128, activation='relu', name='dense1')
        self.dense2 = tf.keras.layers.Dense(128, activation='relu', name='dense2')
        self.out = tf.keras.layers.Dense(action_space_size, activation=None, name='out')

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(inputs)
        return self.out(x)

# Define the DoubleDQN model architecture used in double_dqn.py and double_dqn_agent.py
class DoubleDQN(tf.keras.Model):
    def __init__(self, action_space_size):
        super(DoubleDQN, self).__init__()
        self.dense1 = tf.keras.layers.Dense(128, activation='relu', name='dense1')
        self.dense2 = tf.keras.layers.Dense(128, activation='relu', name='dense2')
        self.out = tf.keras.layers.Dense(action_space_size, activation=None, name='out')

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(inputs)
        return self.out(x)

# Function to create a DQN model instance with the correct architecture
def create_dqn_model(action_space_size, input_shape):
    model = DQN(action_space_size)
    model.build(input_shape)
    return model

# Function to create a DoubleDQN model instance with the correct architecture
def create_double_dqn_model(action_space_size, input_shape):
    model = DoubleDQN(action_space_size)
    model.build(input_shape)
    return model

# Function to manually load weights from HDF5 file
def manual_load_weights(model, file_path):
    with h5py.File(file_path, 'r') as f:
        for layer in model.layers:
            if layer.name in f:
                layer_weights = [f[layer.name]['vars'][str(i)][...] for i in range(len(f[layer.name]['vars']))]
                layer.set_weights(layer_weights)

# Function to load weights and return the model
def load_model_weights(file_path, model_type, action_space_size, input_shape):
    if model_type == 'dqn':
        model = create_dqn_model(action_space_size, input_shape)
    elif model_type == 'double_dqn':
        model = create_double_dqn_model(action_space_size, input_shape)
    else:
        raise ValueError("Unsupported model type.")

    manual_load_weights(model, file_path)
    return model

# Function to extract weights from the model and return them as dataframes
def extract_weights(model):
    weights = {}
    for layer in model.layers:
        layer_weights = layer.get_weights()
        if layer_weights:
            weights[layer.name] = {'weights': pd.DataFrame(layer_weights[0]), 'biases': pd.DataFrame(layer_weights[1])}
    return weights

# Function to load and return Q-learning weights
def load_q_learning_weights(file_path):
    with open(file_path, 'rb') as f:
        q_table = np.load(f)
    return pd.DataFrame(q_table)

# Define the input shape used during training
input_shape = (None, 8400)  # Flattened input shape based on the preprocessing

# List of model files and their types
model_files = [
    ('dqn_model_final.weights.h5', 'dqn'),
    ('double_dqn_model_final.weights.h5', 'double_dqn'),
    ('dqn_model_hyperparameters_final.weights.h5', 'dqn'),
    ('dqn_model_exploration_final.weights.h5', 'dqn'),
    ('dqn_model_exploitation_final.weights.h5', 'dqn'),
    ('q_learning_model_final.weights.h5', 'q_learning')
]

# Dictionary to store model weights
all_model_weights = {}

# Load and extract weights for all models
for file_name, model_type in model_files:
    if model_type == 'q_learning':
        q_table = load_q_learning_weights(file_name)
        all_model_weights[file_name] = q_table
    else:
        model = load_model_weights(file_name, model_type, 9, input_shape)
        all_model_weights[file_name] = extract_weights(model)

# Combine all weights into a single DataFrame
combined_weights = []

for file_name, weights in all_model_weights.items():
    if isinstance(weights, pd.DataFrame):
        weights = weights.reset_index()
        weights['file_name'] = file_name
        weights['layer_name'] = 'q_learning'
        combined_weights.append(weights)
    else:
        for layer_name, layer_data in weights.items():
            weights_df = layer_data['weights'].reset_index()
            weights_df['file_name'] = file_name
            weights_df['layer_name'] = f"{layer_name}_weights"
            combined_weights.append(weights_df)
            
            biases_df = layer_data['biases'].reset_index()
            biases_df['file_name'] = file_name
            biases_df['layer_name'] = f"{layer_name}_biases"
            combined_weights.append(biases_df)

# Save the combined weights to a single CSV file
combined_weights_df = pd.concat(combined_weights, ignore_index=True)
combined_weights_df.to_csv("combined_model_weights.csv", index=False)

